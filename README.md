# ğŸ©º Medical Chatbot â€“ Local AI-Powered Health Q&A Assistant

This project is a locally hosted **medical chatbot** that answers a wide range of health-related queries using information from preloaded medical documents. It combines retrieval-augmented generation (RAG) with open-source tools like **LangChain**, **Ollama**, **FAISS**, and **Streamlit** to deliver private, fast, and context-aware answers â€” all offline.

---

## ğŸ” Features

- ğŸ’¬ Chat interface for asking health-related queries
- ğŸ§  Powered by **Mistral 7B** LLM running locally via Ollama
- ğŸ” Retrieves relevant information using **FAISS vector store**
- ğŸ“„ Medical PDFs preloaded and processed for context
- ğŸ“Œ Responses are strictly based on document content
- âš¡ Caching improves speed for repeated usage
- ğŸ” Entirely offline â€” no internet or API needed

---

## ğŸ§° Tech Stack

| Component            | Tool / Library                                 |
|---------------------|------------------------------------------------|
| LLM Backend          | `mistral:7b` via Ollama                        |
| Document Loading     | `DirectoryLoader`, `PyPDFLoader`              |
| Text Chunking        | `RecursiveCharacterTextSplitter`              |
| Embedding Model      | `all-MiniLM-L6-v2` (HuggingFace)              |
| Vector Store         | FAISS                                          |
| Retrieval Logic      | LangChainâ€™s `RetrievalQA`                     |
| Chat Interface       | Streamlit                                     |

## ğŸ“¸ Screenshot
![Medical Chatbot](https://github.com/SANSKARKURUDE/Medical-Chatbot/blob/main/Screenshot%202025-07-10%20133259.png)
